{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4729d7-45e3-4862-a820-49997a9a90e3",
   "metadata": {},
   "source": [
    "## ğŸ”í¬ë¡¤ë§\n",
    "\n",
    "### **BeautifulSoup4**\n",
    "- íŒŒì´ì¬ì—ì„œ HTML ë° XML ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ì—¬ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- ì›¹ í¬ë¡¤ë§ì´ë‚˜ ìŠ¤í¬ë˜í•‘ ì‘ì—…ì— ìì£¼ ì‚¬ìš©, requestsì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ì›¹ í˜ì´ì§€ì˜ ì •ë³´ë¥¼ ì†ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "#### 1. **ì„¤ì¹˜**\n",
    "```bash\n",
    "# beautifulsoup ì„¤ì¹˜\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# requests - ì›¹ í˜ì´ì§€ ìš”ì²­ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "pip install requests\n",
    "```\n",
    "\n",
    "#### 2. **ê¸°ë³¸ ì‚¬ìš©ë²•**\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://example.com'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')  # ë˜ëŠ” 'lxml'\n",
    "    print(soup.prettify())  # HTML êµ¬ì¡°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "```\n",
    "\n",
    "#### 3. **ì£¼ìš” ë©”ì„œë“œ**\n",
    "**3-1. íƒœê·¸ ì´ë¦„ìœ¼ë¡œ ìš”ì†Œ ì°¾ê¸°**\n",
    "```python\n",
    "# <title> íƒœê·¸ ì „ì²´\n",
    "soup.title  \n",
    "# <title> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë§Œ\n",
    "soup.title.string  \n",
    "# ì²« ë²ˆì§¸ <a> íƒœê·¸\n",
    "soup.a \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-2. `find()`ì™€ `find_all()`**\n",
    "```python\n",
    "# ì²« ë²ˆì§¸ <a> íƒœê·¸\n",
    "soup.find('a')  \n",
    "# classê°€ 'link'ì¸ ì²« ë²ˆì§¸ <a> íƒœê·¸\n",
    "soup.find('a', class_='link')  \n",
    "# classë¡œ ì„ íƒì‹œ class_ ë¼ê³  ëª…ì‹œí•˜ì§€ ì•Šê³  ìƒëµ ê°€ëŠ¥\n",
    "soup.find('a', 'link')  \n",
    "# attrs ë”•ì…”ë„ˆë¦¬ ì´ìš©í•˜ì—¬ ì—¬ëŸ¬ ì†ì„±ì„ ë™ì‹œì— ì§€ì •í•˜ê¸°\n",
    "soup.find('a', attrs={'id' : 'id_name', class_ : 'link'})\n",
    "# idê°’ìœ¼ë¡œ ì°¾ê¸°\n",
    "soup.find(id='id_name')\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# ëª¨ë“  <a> íƒœê·¸ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜\n",
    "soup.find_all('a') \n",
    "\n",
    "```\n",
    "**ğŸ’¡í¬ë¡¤ë§ ì‹œ `class`ë¡œ ë§ì´ ì„ íƒí•œë‹¤**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-3.CSS ì„ íƒì ì‚¬ìš© `select()` & `selet_one()`**\n",
    "```python\n",
    "# classê°€ 'classname'ì¸ ëª¨ë“  <div> íƒœê·¸\n",
    "soup.select('div.classname')  \n",
    "  # idê°€ 'id'ì¸ ì²« ë²ˆì§¸ íƒœê·¸\n",
    "soup.select_one('#id')\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-4.í…ìŠ¤íŠ¸ ë° ì†ì„± ì¶”ì¶œ**\n",
    "```python\n",
    "tag = soup.find('a')\n",
    "\n",
    "# íƒœê·¸ ë‚´ë¶€ì˜ í…ìŠ¤íŠ¸\n",
    "tag.get_text()\n",
    "\n",
    "# get() ë©”ì„œë“œ -> ì†ì„±ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° `None`ì„ ë°˜í™˜í•˜ë¯€ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ë” ì•ˆì „í•˜ê²Œ ì†ì„±ê°’ ì¶”ì¶œ ê°€ëŠ¥\n",
    "href = tag.get('href')\n",
    "href = tag.get('title')\n",
    "\n",
    "# href ì†ì„± ê°’ -> ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° `KeyError`ë¥¼ ë°œìƒì‹œí‚´\n",
    "tag['href']\n",
    "tag['title']\n",
    "\n",
    "# ëª¨ë“  ì†ì„± ë”•ì…”ë„ˆë¦¬\n",
    "tag.attrs  # {'href' : 'https://example.com', 'title' : 'Ex'}\n",
    "\n",
    "```\n",
    "\n",
    "**3-5.ê·¸ ì™¸**\n",
    "```python\n",
    "# íŠ¹ì • ì†ì„± ì¡´ì¬ í™•ì¸ : has_attr()\n",
    "if tag.has_attr('href') :\n",
    "    print('ë§í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤')\n",
    "```\n",
    "\n",
    "[**ğŸ’¡ê³µì‹ë¬¸ì„œ**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73313db7-58b1-4dda-a02c-388109c4059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\"ì´ˆë“±êµì‹¤ì„œ êµì‚¬ê°€ ë¶€ì ì ˆí•œ í–‰ìœ„\" ë¯¼ì›â€¦ ë‹¹ì‚¬ìëŠ” ë¶€ì¸ [ì´ìŠˆë„¤ì»·]>\n",
      "<ì´ì°½ìˆ˜ ì¤‘ì•™ì§€ê²€ì¥, ë³µê·€ ë‘ ë‹¬ ë§Œì— ì‚¬ì˜â€¦\"ê±´ê°•ìƒ ì´ìœ \"(ì¢…í•©)>\n",
      "<[ì†ë³´] ì´ì°½ìˆ˜ ì„œìš¸ì¤‘ì•™ì§€ê²€ì¥Â·ì¡°ìƒì› ì„œìš¸ì¤‘ì•™ì§€ê²€ 4ì°¨ì¥ ì‚¬ì˜>\n",
      "<ìŠ¤íŠ¸ë ˆìŠ¤ DSR â€˜ì™„ì „ì²´â€™ í™•ì •â€¦ëŒ€ì¶œ ì–¼ë§ˆë‚˜ ì¤„ì–´ë“œë‚˜?>\n",
      "<ë‚® ìµœê³  ë‚¨ì› 31.9ë„.. ì˜¬ ë“¤ì–´ ê°€ì¥ ë”ì›Œ>\n",
      "<5ê°œì›”ê°„ ë¹„ìƒê³„ì—„ ê°™ì€ ì¼ ê²ªì€ 'ì‹œì‚¬ê¸°íš ì°½' ê¸°ìë“¤>\n",
      "<ì¤‘êµ­, ê¸°ì¤€ ëŒ€ì¶œê¸ˆë¦¬ ì „ê²© ì¸í•˜â€¦ê²½ê¸°ë¶€ì–‘ì— 'í†µí™”ì™„í™” ì¹´ë“œ' êº¼ë‚´>\n",
      "<ê¹€ë¬¸ìˆ˜ \"ë°©íƒ„ìœ ë¦¬ ì³ë†“ì€ ì‚¬ëŒì´ ëŒ€í†µë ¹ ë˜ë©´ ë˜ê² ë‚˜â€¦ë‚œ ì´ ë§ì„ ì¼ ìˆìœ¼ë©´ ë§ê² ë‹¤\">\n",
      "<[ë‹¨ë…] ìœ¤ì„ì—´, ë…¸íƒ€ì´ë¡œ ì§€í†µì‹¤ ì…ì¥â€¦ê·¸ë‚  'CCTV ì¥ë©´' ì…ìˆ˜>\n",
      "<ê¸°ë…êµ 543ê°œ ë‹¨ì²´ ì—°í•©, ê¹€ë¬¸ìˆ˜ ì§€ì§€ ì„ ì–¸â€¦\"ë‹¤ìŒ ì„¸ëŒ€ ì§€í‚¬ ìœ ì¼í•œ ì„ íƒì§€\">\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com/'\n",
    "res = requests.get(url)\n",
    "title_li = list()\n",
    "\n",
    "if res.status_code == 200 :\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    for text in soup.find_all('strong',class_='cnf_news_title', limit=10) :\n",
    "        title_li.append(text.get_text())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "for title in title_li :\n",
    "    print(f\"<{title}>\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5177421-65a2-4db1-86a7-9ee342178a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### ì—°ìŠµ #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "439106dd-0cc6-4e73-b64a-600f4af297ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë‚˜ë§Œì˜ ì—£ì§€ìˆëŠ” ë¸”ë¡œê·¸ ì‚¬ì´íŠ¸ ë§Œë“¤ê¸°]\n",
      "(ì™•ì´ˆë³´) - í´ë˜ìŠ¤ ì†Œê°œ -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - ë¸”ë¡œê·¸ ê°œë°œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ ì¤€ë¹„í•˜ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - Github pages ì„¤ì •í•´ì„œ ë¸”ë¡œê·¸ ì²« í˜ì´ì§€ ë§Œë“¤ì–´ë³´ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - ì´ˆê°„ë‹¨ í˜ì´ì§€ ë§Œë“¤ì–´ë³´ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - ì´ì˜ê²Œ í…Œë§ˆ ì ìš©í•´ë³´ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - ë§ˆí¬ë‹¤ìš´ ê¸°ì´ˆ ì´í•´í•˜ê³ , ì‹¤ì œ ë‚˜ë§Œì˜ ë¸”ë¡œê·¸ í˜ì´ì§€ ë§Œë“¤ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì™•ì´ˆë³´) - ë‹¤ì–‘í•œ ë§ˆí¬ë‹¤ìš´ ê¸°ë²• ìµí˜€ë³´ë©°, ë‚˜ë§Œì˜ ë¸”ë¡œê·¸ í˜ì´ì§€ ê¾¸ë©°ë³´ê¸° -> ë§í¬ : https://www.fun-coding.org\n",
      "\n",
      "\n",
      "[ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ì— íŒŒì´ì¬ì„ ì…íˆì„¸ìš”! ìì‹ ë§Œì˜ ìë™ í”„ë¡œê·¸ë¨ê¹Œì§€ ê°€ì ¸ê°€ëŠ” íŠ¹ë³„í•œ ê°•ì˜]\n",
      "(ì´ˆê¸‰) - ê°•ì‚¬ê°€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ìë™ í”„ë¡œê·¸ë¨ ì†Œê°œ [2] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œì—° [5] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë§Œë“¤ê¸° [9] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - Â Â Â Â ì—‘ì…€ íŒŒì¼ ì´ì˜ê²Œ! ì´ì˜ê²Œ! [8] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - Â Â Â Â ë‚˜ëŒ€ì‹  ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ ì‹¤í–‰í•˜ê¸° [7] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - íŒŒì´ì¬ìœ¼ë¡œ ìŠ¬ë™(slack) ë©”ì‹ ì €ì— ê¸€ì“°ê¸° [40] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - ì›¹ì‚¬ì´íŠ¸ ë³€ê²½ì‚¬í•­ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•´ì„œ, ë©”ì‹ ì €ë¡œ ì•ŒëŒì£¼ê¸° [12] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì´ˆê¸‰) - ë„¤ì´ë²„ API ì‚¬ìš©í•´ì„œ, ë¸”ë¡œê·¸ì— ê¸€ì“°ê¸° [42] -> ë§í¬ : https://www.fun-coding.org\n",
      "(ì¤‘ê¸‰) - ìë™ìœ¼ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ API ë¡œ ê°€ì ¸ì˜¨ ìƒí’ˆ ì •ë³´, ë„¤ì´ë²„ ë¸”ë¡œê·¸/íŠ¸ìœ„í„°ì— í™ë³´í•˜ê¸° [412] -> ë§í¬ : https://www.fun-coding.org\n"
     ]
    }
   ],
   "source": [
    "url2 = 'https://davelee-fun.github.io/blog/crawl_test'\n",
    "res2 = requests.get(url2)\n",
    "\n",
    "if res2.status_code == 200 :\n",
    "    soup = BeautifulSoup(res2.content, 'html.parser')\n",
    "    hobby_list = soup.select('ul#hobby_course_list .course a')\n",
    "    dev_list = soup.select('ul#dev_course_list .course a')\n",
    "\n",
    "    print(f\"[{soup.select('h3')[0].string}]\")\n",
    "    for elem in hobby_list :\n",
    "        print(f\"{elem.string} -> ë§í¬ : {elem.get('href')}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(f\"[{soup.select('h3')[1].string}]\")\n",
    "    for elem in dev_list :\n",
    "        print(f\"{elem.string} -> ë§í¬ : {elem.get('href')}\")\n",
    "    \n",
    "        \n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a1d86-05c4-407c-8f5c-09d576a6ae73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bb88e-f694-4e62-8a05-67144e5935b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e8107-06ae-45c1-b257-7c9490a7a77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95de93-6b71-48af-a8e4-e549ba90d1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2945d78e-b3b9-4973-bc8e-329af9fe9f83",
   "metadata": {},
   "source": [
    "### ğŸ”– ì°¸ê³ (ì¸ìš©)\n",
    "> [ì¸í”„ëŸ°: íŒŒì´ì¬ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘í•˜ê¸° - ê¸°ë³¸í¸](https://www.inflearn.com/course/python-crawling-basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2181d6-259f-4985-b08b-f86fd5c96c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
