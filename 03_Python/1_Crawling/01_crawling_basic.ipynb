{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4729d7-45e3-4862-a820-49997a9a90e3",
   "metadata": {},
   "source": [
    "## 🔎크롤링\n",
    "\n",
    "### **BeautifulSoup4**\n",
    "- 파이썬에서 HTML 및 XML 문서를 파싱하여 원하는 데이터를 추출할 수 있도록 도와주는 라이브러리\n",
    "- 웹 크롤링이나 스크래핑 작업에 자주 사용, requests와 함께 사용하면 웹 페이지의 정보를 손쉽게 가져올 수 있다.\n",
    "\n",
    "#### 1. **설치**\n",
    "```bash\n",
    "# beautifulsoup 설치\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# requests - 웹 페이지 요청 라이브러리\n",
    "pip install requests\n",
    "```\n",
    "\n",
    "#### 2. **기본 사용법**\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://example.com'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')  # 또는 'lxml'\n",
    "    print(soup.prettify())  # HTML 구조를 보기 좋게 출력\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "```\n",
    "\n",
    "#### 3. **주요 메서드**\n",
    "**3-1. 태그 이름으로 요소 찾기**\n",
    "```python\n",
    "# <title> 태그 전체\n",
    "soup.title  \n",
    "# <title> 태그의 텍스트만\n",
    "soup.title.string  \n",
    "# 첫 번째 <a> 태그\n",
    "soup.a \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-2. `find()`와 `find_all()`**\n",
    "```python\n",
    "# 첫 번째 <a> 태그\n",
    "soup.find('a')  \n",
    "# class가 'link'인 첫 번째 <a> 태그\n",
    "soup.find('a', class_='link')  \n",
    "# class로 선택시 class_ 라고 명시하지 않고 생략 가능\n",
    "soup.find('a', 'link')  \n",
    "# attrs 딕셔너리 이용하여 여러 속성을 동시에 지정하기\n",
    "soup.find('a', attrs={'id' : 'id_name', class_ : 'link'})\n",
    "# id값으로 찾기\n",
    "soup.find(id='id_name')\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# 모든 <a> 태그 리스트 형태로 반환\n",
    "soup.find_all('a') \n",
    "\n",
    "```\n",
    "**💡크롤링 시 `class`로 많이 선택한다**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-3.CSS 선택자 사용 `select()` & `selet_one()`**\n",
    "```python\n",
    "# class가 'classname'인 모든 <div> 태그\n",
    "soup.select('div.classname')  \n",
    "  # id가 'id'인 첫 번째 태그\n",
    "soup.select_one('#id')\n",
    "\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**3-4.텍스트 및 속성 추출**\n",
    "```python\n",
    "tag = soup.find('a')\n",
    "# 태그 내부의 텍스트\n",
    "tag.get_text()\n",
    "# href 속성 값\n",
    "tag['href']\n",
    "# 모든 속성 딕셔너리\n",
    "tag.attrs  \n",
    "\n",
    "```\n",
    "\n",
    "[**💡공식문서**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73313db7-58b1-4dda-a02c-388109c4059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\"초등교실서 교사가 부적절한 행위\" 민원… 당사자는 부인 [이슈네컷]>\n",
      "<이창수 중앙지검장, 복귀 두 달 만에 사의…\"건강상 이유\"(종합)>\n",
      "<[속보] 이창수 서울중앙지검장·조상원 서울중앙지검 4차장 사의>\n",
      "<스트레스 DSR ‘완전체’ 확정…대출 얼마나 줄어드나?>\n",
      "<낮 최고 남원 31.9도.. 올 들어 가장 더워>\n",
      "<5개월간 비상계엄 같은 일 겪은 '시사기획 창' 기자들>\n",
      "<중국, 기준 대출금리 전격 인하…경기부양에 '통화완화 카드' 꺼내>\n",
      "<김문수 \"방탄유리 쳐놓은 사람이 대통령 되면 되겠나…난 총 맞을 일 있으면 맞겠다\">\n",
      "<[단독] 윤석열, 노타이로 지통실 입장…그날 'CCTV 장면' 입수>\n",
      "<기독교 543개 단체 연합, 김문수 지지 선언…\"다음 세대 지킬 유일한 선택지\">\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com/'\n",
    "res = requests.get(url)\n",
    "title_li = list()\n",
    "\n",
    "if res.status_code == 200 :\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    for text in soup.find_all('strong',class_='cnf_news_title', limit=10) :\n",
    "        title_li.append(text.get_text())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\n",
    "for title in title_li :\n",
    "    print(f\"<{title}>\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5177421-65a2-4db1-86a7-9ee342178a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439106dd-0cc6-4e73-b64a-600f4af297ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a1d86-05c4-407c-8f5c-09d576a6ae73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bb88e-f694-4e62-8a05-67144e5935b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e8107-06ae-45c1-b257-7c9490a7a77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95de93-6b71-48af-a8e4-e549ba90d1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2945d78e-b3b9-4973-bc8e-329af9fe9f83",
   "metadata": {},
   "source": [
    "### 🔖 참고(인용)\n",
    "> [인프런: 파이썬으로 크롤링 시작하기 - 기본편](https://www.inflearn.com/course/python-crawling-basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2181d6-259f-4985-b08b-f86fd5c96c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
